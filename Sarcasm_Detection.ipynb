{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KeXSQuC5edYz"
   },
   "source": [
    "# **Sarcasm Detection in News Headlines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4R0ugebCNMEO"
   },
   "source": [
    "The purpose of this project is to build a tool to be able to detect sarcasm in sentences. \n",
    "\n",
    "**Data**: The data we are working with is headlines from various news articles marked as either sarcastic or not sarcastic. The columns in the dataset are:\n",
    "1. The headline\n",
    "2. The article's link (we'll disregard this column)\n",
    "3. Label of whether the headline is sarcastic or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5tARTnbKZY2L",
    "outputId": "fa5ca2a9-ecd2-45d2-b9a6-3786d4998805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#@title Package imports\n",
    "#Import\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Embedding, LSTM, GlobalAveragePooling1D, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "import random\n",
    "\n",
    "random.seed(9176932)\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "yxqpcLwhZdEJ",
    "outputId": "73ed9c44-9c35-4154-d701-a753b92f51aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#@title Google drive mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RZP6p8fzZfBK"
   },
   "outputs": [],
   "source": [
    "#@title Data read-in\n",
    "#reading in the file\n",
    "sarcasm_master = pd.read_json(\"/content/gdrive/My Drive/Data Mining II/sarcasm_master.json\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKwqjNS8N1-z"
   },
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "Before we can feed the data to our model, we need to perform a few data preprocessing operations. \n",
    "\n",
    "1. **Removing punctuations**:\n",
    "   \n",
    "   Most text contains punctuations. In detecting sarcasm, the presence of punctuations doesn't necesarily contribute to the model performing better. So we aim to strip the data of all punctuations.\n",
    "\n",
    "2. **Remove digits**:\n",
    "    \n",
    "    We are going to vectorize our data and convert the strings to numbers. Presence of numbers in the data would not help in identifying the tone any better. Moreover the pre-existing digits might interfere with the vectorization process. Hence all numbers are removed as well.\n",
    "\n",
    "3. **Converting to lower case**: \n",
    "  \n",
    "    Converting the text to lower case helps make the data uniform.\n",
    "\n",
    "4. **Removing stop words**:\n",
    "\n",
    "    Most headlines or any natural language data would contain stop words that are usually removed as stop words generally appear in abundance and do not provide any valuable information during classification.\n",
    "\n",
    "5. **Lemmatization**:\n",
    "\n",
    "    Lemmatization is the process by which any inflected version of a word is converted to its base word so that all forms of a word are treated the same.\n",
    "\n",
    "6. **Vectorization and padding**:\n",
    "\n",
    "    Vectorization is the process by which words are mapped to the numeric vectors. For LSTM model, the input should be of same size. Hence we pad the vectors with zeros to ensure unformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "dUmHQYpdZrMC"
   },
   "outputs": [],
   "source": [
    "#@title Prelim text processing\n",
    "#Removing punctuation and digits and converting to lower case\n",
    "#Punctuation\n",
    "sarcasm_master['punct_headline'] = sarcasm_master['headline'].apply(lambda x : re.sub(r'[^a-zA-Z\\s]','', x ) )\n",
    "\n",
    "#Removing digits\n",
    "sarcasm_master['digits_headline'] = sarcasm_master['punct_headline'].apply(lambda x :re.sub(\"\\d+\", \"\", x)) \n",
    "\n",
    "#Converting to lower case\n",
    "sarcasm_master['lc_headline'] = sarcasm_master['digits_headline'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "gtnJ9kXrZthm"
   },
   "outputs": [],
   "source": [
    "#@title Remove stop words\n",
    "def rem_stp(input_series):\n",
    "    words = word_tokenize(input_series)\n",
    "    a = [w for w in words] \n",
    "    return(a)\n",
    "\n",
    "sarcasm_master['rem_stp_headline'] = sarcasm_master['lc_headline'].apply(rem_stp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "Xtp4-HKqZt6-"
   },
   "outputs": [],
   "source": [
    "#@title Lemmatization\n",
    "#Lemmatization\n",
    "lmt = WordNetLemmatizer()\n",
    "def lem_fn(input_series):\n",
    "    a  =  [lmt.lemmatize(word) for word in input_series ]\n",
    "    return(a)\n",
    "\n",
    "sarcasm_master['lem_headline'] = sarcasm_master['rem_stp_headline'].apply(lem_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "lG8YZ6IIbUSl"
   },
   "outputs": [],
   "source": [
    "#@title Vectorization\n",
    "#Vectorization \n",
    "\n",
    "tkn = Tokenizer(num_words=10000)\n",
    "tkn.fit_on_texts(sarcasm_master['lem_headline'])\n",
    "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['lem_headline'])\n",
    "\n",
    "total_words = len(tkn.word_index)\n",
    "\n",
    "#Add padding in front for the tokenized list\n",
    "\n",
    "#Find max length of the headline array length to add as maximum pad length\n",
    "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fx8ud3usulCI"
   },
   "source": [
    "# **Building Keras Model**\n",
    "\n",
    "We are going to be building a Keras Model.\n",
    "\n",
    "1. **Embedding layer**\n",
    "\n",
    "   The Embedding layer is used to create word vectors for incoming words. It sits between the input and the LSTM layer, i.e. the output of the Embedding layer is the input to the LSTM layer.\n",
    "\n",
    "2. **LSTM Layer**\n",
    "\n",
    " The LSTM transforms the vector sequence into a single vector containing information about the entire sequence.\n",
    "\n",
    "3. **Intermediate Layer**\n",
    "   \n",
    "   There is a Dense intermediate layer with 64 neurons and with activation function **relu**.\n",
    "\n",
    "4. **Output Layer**\n",
    "    \n",
    "    The final ouput we want from this model is whether the headline is sarcastic or not. So we want to perform classification. The output layer's activation function is thus **sigmoid**\n",
    "\n",
    "\n",
    "Reference:\n",
    "\n",
    "Keras : https://keras.io/getting-started/sequential-model-guide/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "PsaCqNMMu_TX"
   },
   "outputs": [],
   "source": [
    "#@title build_model\n",
    "def build_model(X_train, y_train, X_test, y_test):\n",
    "  \n",
    "  embed_size = 128\n",
    "  model = Sequential()\n",
    "  \n",
    "  #Embedding Layer\n",
    "  model.add(Embedding( total_words,embed_size))\n",
    "\n",
    "  #LSTM input layer\n",
    "  model.add(LSTM(embed_size, activation='relu'))\n",
    "  \n",
    "  #Intermediate layer\n",
    "  model.add(Dense(64, activation ='relu'))\n",
    "  \n",
    "  #OutputLayer\n",
    "  model.add(Dense(1))\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "  print(model.summary())\n",
    "\n",
    "  model.fit(X_train,y_train,epochs=2)\n",
    "\n",
    "  accuracy = model.evaluate(X_test, y_test)[1]\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3IfCG7Sa4cz"
   },
   "source": [
    "## **Model 1 - Base model**\n",
    "\n",
    "We first build a base model with the following preprocessing.\n",
    "\n",
    "1. Remove punctuations, digits and convert the text to lowercase.\n",
    "2. Remove all the stopwords\n",
    "3. Perform Lemmatization\n",
    "4. Perform tokenization and pad the resulting sequence - Prepadding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9yrtueNXjOz1",
    "outputId": "69f5a25f-5d86-4cc6-cc09-abf635f5c0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, None, 128)         3094656   \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,234,561\n",
      "Trainable params: 3,234,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.4703 - accuracy: 0.7817\n",
      "Epoch 2/2\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.2369 - accuracy: 0.9053\n",
      "5342/5342 [==============================] - 1s 195us/step\n",
      "0.8496817946434021\n"
     ]
    }
   ],
   "source": [
    "#@title Base Model\n",
    "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
    "sarcasm_master['padded_headline'] = X.tolist()\n",
    "\n",
    "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "base_accuracy = build_model(X_train, y_train, X_test ,y_test )\n",
    "print(base_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lNgC_9AxbzWS"
   },
   "source": [
    "**Results:**\n",
    "\n",
    "We see that we get an accuracy of about 84.9%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYbb5vsfcuhy"
   },
   "source": [
    "## **Model 2 - Post padding**\n",
    "\n",
    "We first build a model very similar to the base model with the following change:\n",
    "After performing the tokenization, do post-padding\n",
    "\n",
    "**Example:**\n",
    "Before padding : [234,5,67,12]\n",
    "\n",
    "The max_length is 7\n",
    "\n",
    "Pre-padding: [0,0,0,0,234,5,67,12]\n",
    "\n",
    "Post-padding: [234,5,67,12,0,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "k34b2Tppc82P",
    "outputId": "ad67c6ea-5e8d-4428-b6c6-3fed585e0d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, None, 128)         3094656   \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,234,561\n",
      "Trainable params: 3,234,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "21367/21367 [==============================] - 49s 2ms/step - loss: 1.0090 - accuracy: 0.5649\n",
      "Epoch 2/2\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.7077 - accuracy: 0.5637\n",
      "5342/5342 [==============================] - 1s 203us/step\n",
      "0.5503556728363037\n"
     ]
    }
   ],
   "source": [
    "#@title Post padding model\n",
    "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='post')\n",
    "sarcasm_master['post_padded_headline'] = X.tolist()\n",
    "\n",
    "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "post_padding_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
    "print(post_padding_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30l-mjJefOX4"
   },
   "source": [
    "**Results**\n",
    "\n",
    "Surprisingly we see a huge drop in the accuracy from **85% to 55%** now.\n",
    "\n",
    "The reason why this is because we are building a Long Short term memory model.\n",
    "When the padding is in the beginning, the useful content is at the back and is therefore the latest information the model takes in. This stays in memory and results in a better model.\n",
    "\n",
    "**We are going to proceed further with pre-padded sequence for future models.**\n",
    "\n",
    "Reference: https://arxiv.org/pdf/1903.07288.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RiIk9isge7H"
   },
   "source": [
    "## **Model 3 - Sans Lemmatization**\n",
    "\n",
    "We now build a model that is a modification of our base model. We want to see the effect of lemmatization. Lemmatization is the process by which any inflected version of a word is converted to its base word so that all forms of a word are treated the same. \n",
    "\n",
    "We want to see if in detecting sarcasm, the **effect of inflect** plays a role in improcing the efficiency of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "a8VAyg1ZhJUP",
    "outputId": "44619281-a2e1-44c5-9ae7-e0b308d7884c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, None, 128)         3534848   \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,674,753\n",
      "Trainable params: 3,674,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.4036 - accuracy: 0.8131\n",
      "Epoch 2/2\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.2062 - accuracy: 0.9192\n",
      "5342/5342 [==============================] - 1s 192us/step\n",
      "0.8567951917648315\n"
     ]
    }
   ],
   "source": [
    "#@title Sans Lemmatization\n",
    "tkn = Tokenizer(num_words=10000)\n",
    "tkn.fit_on_texts(sarcasm_master['rem_stp_headline'])\n",
    "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['rem_stp_headline'])\n",
    "\n",
    "total_words = len(tkn.word_index)\n",
    "\n",
    "#Add padding in front for the tokenized list\n",
    "\n",
    "#Find max length of the headline array length to add as maximum pad length\n",
    "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
    "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
    "sarcasm_master['sanslem_headline'] = X.tolist()\n",
    "\n",
    "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "sans_lemmatization_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
    "print(sans_lemmatization_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJc5zaRpoymG"
   },
   "source": [
    "**Results**\n",
    "\n",
    "We see that not performing lemmatization inproves the accuracy but just slightly from 85% to 85.6%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVKQBk4lpFka"
   },
   "source": [
    "## **Model 4 - Including stop words**\n",
    "\n",
    "We test the effect that stop words have on the model. In general NLP models, we generally remove stop words. But our theory is that the stop words might actually have an effect in identifying the sarcasm in a sentence. \n",
    "\n",
    "We want to see if in detecting sarcasm, the **effect of stop words** plays a role in improving the efficiency of our model.\n",
    "\n",
    "\n",
    "Reference : https://towardsdatascience.com/why-you-should-avoid-removing-stopwords-aa7a353d2a52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "7vGAtVZRpsh4",
    "outputId": "1b9d4ee7-b369-4ef1-8afd-757747c15fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, None, 128)         3094656   \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,234,561\n",
      "Trainable params: 3,234,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.4075 - accuracy: 0.8085\n",
      "Epoch 2/2\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.2220 - accuracy: 0.9109\n",
      "5342/5342 [==============================] - 1s 197us/step\n",
      "0.8547360301017761\n"
     ]
    }
   ],
   "source": [
    "#@title Including stop words\n",
    "\n",
    "#Lemmatization\n",
    "lmt = WordNetLemmatizer()\n",
    "def lem_fn(input_series):\n",
    "    a  =  [lmt.lemmatize(word) for word in input_series ]\n",
    "    return(a)\n",
    "\n",
    "sarcasm_master['lem_headline'] = sarcasm_master['rem_stp_headline'].apply(lem_fn) \n",
    "\n",
    "tkn = Tokenizer(num_words=10000)\n",
    "tkn.fit_on_texts(sarcasm_master['lem_headline'])\n",
    "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['lem_headline'])\n",
    "\n",
    "total_words = len(tkn.word_index)\n",
    "\n",
    "#Add padding in front for the tokenized list\n",
    "\n",
    "#Find max length of the headline array length to add as maximum pad length\n",
    "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
    "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
    "sarcasm_master['sanslem_headline'] = X.tolist()\n",
    "\n",
    "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "include_sw_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
    "print(include_sw_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSdED7yFrsiZ"
   },
   "source": [
    "**Results**:\n",
    "\n",
    "We see that the accuracy hasn't increased too much from the base model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbWS1ebnDadL"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "We now want to focus on hyperparameter tunings. \n",
    "The various parameters in consideration are \n",
    "1. Layer activation\n",
    "2. Number of epochs\n",
    "3. Optimizer, etc\n",
    "\n",
    "We are going to use **Grid search** for selecting the best parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCnjalz88T3g"
   },
   "outputs": [],
   "source": [
    "#Vectorization \n",
    "\n",
    "tkn = Tokenizer(num_words=10000)\n",
    "tkn.fit_on_texts(sarcasm_master['rem_stp_headline'])\n",
    "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['rem_stp_headline'])\n",
    "\n",
    "total_words = len(tkn.word_index)\n",
    "\n",
    "#Add padding in front for the tokenized list\n",
    "\n",
    "#Find max length of the headline array length to add as maximum pad length\n",
    "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
    "\n",
    "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
    "sarcasm_master['final_headline'] = X.tolist()\n",
    "\n",
    "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1xHgg_pJ08J"
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', activation='relu'):\n",
    "  embed_size = 128\n",
    "  model = Sequential()\n",
    "  \n",
    "  #Embedding Layer\n",
    "  model.add(Embedding( total_words,embed_size))\n",
    "\n",
    "  #LSTM input layer\n",
    "  model.add(LSTM(embed_size, activation='relu'))\n",
    "  \n",
    "  #Intermediate layer\n",
    "  model.add(Dense(64, activation ='relu'))\n",
    "  \n",
    "  #OutputLayer\n",
    "  model.add(Dense(1))\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "id": "1sPKhOiIKO6F",
    "outputId": "537d94ca-cb0c-4e69-bb8e-2c92fd0b6b83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 0.4031 - accuracy: 0.8132\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 0.2000 - accuracy: 0.9222\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 76s 4ms/step - loss: 0.4133 - accuracy: 0.8088\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 76s 4ms/step - loss: 0.2148 - accuracy: 0.9146\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 0.4340 - accuracy: 0.8044\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 0.2107 - accuracy: 0.9138\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 80s 4ms/step - loss: 0.4175 - accuracy: 0.8034\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 80s 4ms/step - loss: 0.2093 - accuracy: 0.9158\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 81s 5ms/step - loss: 0.5581 - accuracy: 0.8035\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 80s 5ms/step - loss: 0.2072 - accuracy: 0.9171\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 0.4116 - accuracy: 0.8075\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 76s 4ms/step - loss: 0.1993 - accuracy: 0.9195\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 78s 4ms/step - loss: 0.4160 - accuracy: 0.8064\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 78s 4ms/step - loss: 0.2083 - accuracy: 0.9165\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 80s 4ms/step - loss: 0.4384 - accuracy: 0.8041\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 80s 5ms/step - loss: 0.2127 - accuracy: 0.9143\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 79s 4ms/step - loss: 0.4811 - accuracy: 0.8074\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 78s 4ms/step - loss: 0.1985 - accuracy: 0.9213\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 80s 4ms/step - loss: 0.4057 - accuracy: 0.8111\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 79s 4ms/step - loss: 0.2033 - accuracy: 0.9190\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 76s 4ms/step - loss: 0.4537 - accuracy: 0.8073\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 76s 4ms/step - loss: 0.2179 - accuracy: 0.9154\n",
      "Epoch 1/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 9045.9316 - accuracy: 0.7312\n",
      "Epoch 2/2\n",
      "17806/17806 [==============================] - 77s 4ms/step - loss: 1.8293 - accuracy: 0.8660\n",
      "Epoch 1/2\n",
      "26709/26709 [==============================] - 116s 4ms/step - loss: 0.3771 - accuracy: 0.8249\n",
      "Epoch 2/2\n",
      "26709/26709 [==============================] - 115s 4ms/step - loss: 0.2074 - accuracy: 0.9176\n",
      "0.8546557340222397 {'activation': 'relu', 'batch_size': 15, 'epochs': 2, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model1 = KerasClassifier(build_fn=create_model, epochs=2, batch_size=16)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = dict(optimizer=['sgd', 'adam'], \n",
    "              epochs=[2],\n",
    "              batch_size=[15], \n",
    "              activation=['relu','tanh'])\n",
    "\n",
    "# Create a random search cv object and fit it to the data\n",
    "grid_search = GridSearchCV(model1, params, cv=3, scoring='accuracy')\n",
    "random_search_results = grid_search.fit(X, Y)\n",
    "# Print results\n",
    "print(random_search_results.best_score_,random_search_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Y5u6WXUY50zA",
    "outputId": "1e71fc9e-0261-4ba8-c52c-5df998ef236a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21367/21367 [==============================] - 44s 2ms/step - loss: 0.4227 - accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "21367/21367 [==============================] - 44s 2ms/step - loss: 0.2213 - accuracy: 0.9130\n",
      "Epoch 3/5\n",
      "21367/21367 [==============================] - 44s 2ms/step - loss: 0.1267 - accuracy: 0.9511\n",
      "Epoch 4/5\n",
      "21367/21367 [==============================] - 43s 2ms/step - loss: 0.0667 - accuracy: 0.9748\n",
      "Epoch 5/5\n",
      "21367/21367 [==============================] - 44s 2ms/step - loss: 0.0369 - accuracy: 0.9874\n",
      "5342/5342 [==============================] - 1s 195us/step\n",
      "0.8287158608436584\n"
     ]
    }
   ],
   "source": [
    "#Epoch 5 accuracy 82.8%\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "  \n",
    "#Embedding Layer\n",
    "model.add(Embedding( total_words,embed_size))\n",
    "\n",
    "#LSTM input layer\n",
    "model.add(LSTM(embed_size, activation='relu'))\n",
    "  \n",
    "#Intermediate layer\n",
    "model.add(Dense(64, activation ='relu'))\n",
    "  \n",
    "#OutputLayer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=5)\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "ig8vLqBu6Prc",
    "outputId": "22adcb35-7a02-4d00-b749-fb4d5ba6e0e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.4087 - accuracy: 0.8100\n",
      "Epoch 2/10\n",
      "21367/21367 [==============================] - 47s 2ms/step - loss: 0.2072 - accuracy: 0.9170\n",
      "Epoch 3/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.1112 - accuracy: 0.9579\n",
      "Epoch 4/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0590 - accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0358 - accuracy: 0.9875\n",
      "Epoch 6/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0353 - accuracy: 0.9893\n",
      "Epoch 7/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0155 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "21367/21367 [==============================] - 46s 2ms/step - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 10/10\n",
      "21367/21367 [==============================] - 45s 2ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "5342/5342 [==============================] - 1s 199us/step\n",
      "0.8333957195281982\n"
     ]
    }
   ],
   "source": [
    "#Epoch 10 accuracy 84.5%\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "  \n",
    "#Embedding Layer\n",
    "model.add(Embedding( total_words,embed_size))\n",
    "\n",
    "#LSTM input layer\n",
    "model.add(LSTM(embed_size, activation='relu'))\n",
    "  \n",
    "#Intermediate layer\n",
    "model.add(Dense(64, activation ='relu'))\n",
    "  \n",
    "#OutputLayer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=10)\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNV0G0BWC90V"
   },
   "source": [
    "**Results**\n",
    "\n",
    "From the grid search we get the following results:\n",
    "\n",
    "1. The best optimizer for our model is **adam**\n",
    "\n",
    "2. The best activation to use is **relu**\n",
    "\n",
    "We also try various epoch values : 2,5,10\n",
    "\n",
    "2  : Training accuracy- 91.9   Testing accuracy - 85.6\n",
    "\n",
    "5  : Training accuracy- 98.7   Testing accuracy - 82.8\n",
    "\n",
    "10 : Training accuracy- 99.3   Testing accuracy - 83.3\n",
    "\n",
    "We see that for epochs higher than 2, even if the training accuracy increases the testing accuracy goes down. This could be because of overfitting.\n",
    "\n",
    "\n",
    "## **Final Model**\n",
    "\n",
    "The final model we build is a Keras model with LSTM \n",
    "\n",
    "Prepocessing : Removing stop words, punctuations, digits and converting to lower case\n",
    "\n",
    "Epochs : 2\n",
    "\n",
    "Activation : relu\n",
    "\n",
    "Output Activation : sigmoid\n",
    "\n",
    "Optimizer : adam\n",
    "\n",
    "Training accuracy : 91.9%\n",
    "\n",
    "Testing accuracy : 85.6%\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sarcasm_Detection_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
